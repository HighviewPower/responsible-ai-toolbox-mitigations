{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 2 - Multiple Runs\n",
    "\n",
    "## 0 - Defining Basic Functionalities\n",
    "\n",
    "This notebook, as in **case2.ipynb**, we will explore the **wilt** dataset. Similar to **Case1.ipynb/Case1_stat.ipynb**, we will run the same experiment multiple times in order to see if a preprocessing step improves the model's performance with statistical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uci_dataset as database\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import raimitigations.dataprocessing as dp\n",
    "\n",
    "USE_AUC_TH = False\n",
    "\n",
    "RESULT_KEYS = [\"roc\", \"pr\", \"rc\", \"f1\"]\n",
    "COL_METRIC = \"Metric\"\n",
    "COL_VALUE = \"Value\"\n",
    "COL_TEST = \"Test Case\"\n",
    "\n",
    "SEQ_FWD = 0\n",
    "SEQ_BWD = 1\n",
    "CATBOOST = 2\n",
    "\n",
    "# -----------------------------------\n",
    "def remove_corr_feat(df, label_col):\n",
    "\tcor_feat = dp.CorrelatedFeatures(\n",
    "\t\t\t\t\tmethod_num_num=[\"spearman\", \"pearson\", \"kendall\"],\t\t\t\t# Used for Numerical x Numerical correlations\n",
    "\t\t\t\t\tnum_corr_th=0.9,\t\t\t\t\t\t\t\t\t\t\t\t# Used for Numerical x Numerical correlations\n",
    "\t\t\t\t\tnum_pvalue_th=0.05,\t\t\t\t\t\t\t\t\t\t\t\t# Used for Numerical x Numerical correlations\n",
    "\t\t\t\t\tmethod_num_cat=\"model\",\t\t\t\t\t\t\t\t\t\t\t# Used for Numerical x Categorical correlations\n",
    "\t\t\t\t\tmodel_metrics=[\"f1\", \"auc\"],\t\t\t\t\t\t\t\t\t# Used for Numerical x Categorical correlations\n",
    "\t\t\t\t\tmetric_th=0.9,\t\t\t\t\t\t\t\t\t\t\t\t\t# Used for Numerical x Categorical correlations\n",
    "\t\t\t\t\tcat_corr_th=0.9,\t\t\t\t\t\t\t\t\t\t\t\t# Used for Categorical x Categorical correlations\n",
    "\t\t\t\t\tcat_pvalue_th=0.01,\t\t\t\t\t\t\t\t\t\t\t\t# Used for Categorical x Categorical correlations\n",
    "\t\t\t\t\tsave_json=False,\n",
    "\t\t\t\t\tverbose=False\n",
    "\t\t\t\t)\n",
    "\tcor_feat.fit(df=df, label_col=label_col)\n",
    "\tproc_df = cor_feat.transform(df)\n",
    "\treturn proc_df\n",
    "\n",
    "\n",
    "# -----------------------------------\n",
    "def transform_num_data(train_x, test_x, scaler_ref, num_col):\n",
    "\tignore = None\n",
    "\tif num_col is not None:\n",
    "\t\tignore = [col for col in train_x.columns if col not in num_col]\n",
    "\ttransformer = scaler_ref(exclude_cols=ignore, verbose=False)\n",
    "\ttransformer.fit(train_x)\n",
    "\ttrain_x_scl = transformer.transform(train_x)\n",
    "\ttest_x_scl = transformer.transform(test_x)\n",
    "\treturn train_x_scl, test_x_scl\n",
    "\n",
    "# -----------------------------------\n",
    "def feature_selection(train_x, train_y, test_x, feat_sel_type):\n",
    "\tif feat_sel_type == SEQ_FWD:\n",
    "\t\tfeat_sel = dp.SeqFeatSelection(forward=True, n_jobs=4, verbose=False)\n",
    "\telif feat_sel_type == SEQ_BWD:\n",
    "\t\tfeat_sel = dp.SeqFeatSelection(forward=False, n_jobs=4, verbose=False)\n",
    "\telse:\n",
    "\t\tfeat_sel = dp.CatBoostSelection(verbose=False)\n",
    "\tfeat_sel.fit(X=train_x, y=train_y)\n",
    "\ttrain_x_sel = feat_sel.transform(train_x)\n",
    "\ttest_x_sel = feat_sel.transform(test_x)\n",
    "\n",
    "\tfeatures = feat_sel.get_selected_features()\n",
    "\treturn train_x_sel, test_x_sel\n",
    "\n",
    "# -----------------------------------\n",
    "def artificial_smote(train_x, train_y, strategy, under_sample):\n",
    "\trebalance = dp.Rebalance(\n",
    "\t\t\t\tX=train_x,\n",
    "\t\t\t\ty=train_y,\n",
    "\t\t\t\tstrategy_over=strategy,\n",
    "\t\t\t\tover_sampler=True,\n",
    "\t\t\t\tunder_sampler=under_sample,\n",
    "\t\t\t\tverbose=False\n",
    "\t\t\t)\n",
    "\ttrain_x_res, train_y_res = rebalance.fit_resample()\n",
    "\treturn train_x_res, train_y_res\n",
    "\n",
    "# -----------------------------------\n",
    "def artificial_ctgan(train_x, train_y, strategy, savefile):\n",
    "\tsynth = dp.Synthesizer(\n",
    "\t\t\t\tX=train_x,\n",
    "\t\t\t\ty=train_y,\n",
    "\t\t\t\tepochs=1000,\n",
    "\t\t\t\tmodel=\"ctgan\",\n",
    "\t\t\t\tload_existing=True,\n",
    "\t\t\t\tsave_file=savefile,\n",
    "\t\t\t\tverbose=False\n",
    "\t\t\t)\n",
    "\tsynth.fit()\n",
    "\tsyn_train_x, syn_train_y = synth.transform(X=train_x, y=train_y, strategy=strategy)\n",
    "\treturn syn_train_x, syn_train_y\n",
    "\n",
    "# -----------------------------------\n",
    "# -----------------------------------\n",
    "# -----------------------------------\n",
    "def result_statistics(result_list):\n",
    "\tresult_stat = {}\n",
    "\tfor result in result_list:\n",
    "\t\tfor key in RESULT_KEYS:\n",
    "\t\t\tif key in result_stat.keys():\n",
    "\t\t\t\tresult_stat[key].append(result[key])\n",
    "\t\t\telse:\n",
    "\t\t\t\tresult_stat[key] = [result[key]]\n",
    "\n",
    "\treturn result_stat\n",
    "\n",
    "\n",
    "# -----------------------------------\n",
    "def add_results_df(result_df, result_stat, test_name):\n",
    "\tcol_test = []\n",
    "\tcol_metric = []\n",
    "\tcol_value = []\n",
    "\tfor metric in RESULT_KEYS:\n",
    "\t\tcol_value += result_stat[metric]\n",
    "\t\tcol_test += [test_name for _ in range(len(result_stat[metric]))]\n",
    "\t\tcol_metric += [metric for _ in range(len(result_stat[metric]))]\n",
    "\n",
    "\tnew_df = pd.DataFrame()\n",
    "\tnew_df[COL_VALUE] = col_value\n",
    "\tnew_df[COL_TEST] = col_test\n",
    "\tnew_df[COL_METRIC] = col_metric\n",
    "\tnew_df[COL_VALUE] = new_df[COL_VALUE].apply(float)\n",
    "\n",
    "\tif result_df is None:\n",
    "\t\treturn new_df\n",
    "\t\n",
    "\tresult_df = pd.concat([result_df, new_df], axis=0)\n",
    "\t\n",
    "\treturn result_df\n",
    "\n",
    "\n",
    "# -----------------------------------\n",
    "def test_base(df, label_col, n_exec, model_name):\n",
    "\tresult_list = []\n",
    "\tfor n in range(n_exec):\n",
    "\t\ttrain_x, test_x, train_y, test_y = dp.split_data(df, label_col, test_size=0.25)\n",
    "\t\tresult = dp.train_model_fetch_results(train_x, train_y, test_x, test_y, model_name, USE_AUC_TH)\n",
    "\t\tresult_list.append(result)\n",
    "\n",
    "\tresult_stat = result_statistics(result_list)\n",
    "\n",
    "\treturn result_stat\n",
    "\n",
    "\n",
    "# -----------------------------------\n",
    "def test_corr(df, label_col, n_exec, model_name):\n",
    "\tresult_list = []\n",
    "\tproc_df = remove_corr_feat(df, label_col)\n",
    "\tfor n in range(n_exec):\n",
    "\t\ttrain_x, test_x, train_y, test_y = dp.split_data(proc_df, label_col, test_size=0.25)\n",
    "\t\tresult = dp.train_model_fetch_results(train_x, train_y, test_x, test_y, model_name, USE_AUC_TH)\n",
    "\t\tresult_list.append(result)\n",
    "\n",
    "\tresult_stat = result_statistics(result_list)\n",
    "\n",
    "\treturn result_stat\n",
    "\n",
    "\n",
    "# -----------------------------------\n",
    "def test_corr_transf(df, label_col, n_exec, scaler_ref, model_name, num_col=None):\n",
    "\tresult_list = []\n",
    "\tproc_df = remove_corr_feat(df, label_col)\n",
    "\tfor n in range(n_exec):\n",
    "\t\ttrain_x, test_x, train_y, test_y = dp.split_data(proc_df, label_col, test_size=0.25)\n",
    "\t\ttrain_x, test_x = transform_num_data(train_x, test_x, scaler_ref, num_col)\n",
    "\t\tresult = dp.train_model_fetch_results(train_x, train_y, test_x, test_y, model_name, USE_AUC_TH)\n",
    "\t\tresult_list.append(result)\n",
    "\n",
    "\tresult_stat = result_statistics(result_list)\n",
    "\n",
    "\treturn result_stat\n",
    "\n",
    "# -----------------------------------\n",
    "def test_smote_transf(df, label_col, n_exec, model_name, rcorr=True, scaler_ref=None, num_col=None, feat_sel_type=None, art_str=None, under=False):\n",
    "\tresult_list = []\n",
    "\tproc_df = df\n",
    "\tif rcorr:\n",
    "\t\tproc_df = remove_corr_feat(proc_df, label_col)\n",
    "\tfor n in range(n_exec):\n",
    "\t\ttrain_x, test_x, train_y, test_y = dp.split_data(proc_df, label_col, test_size=0.25)\n",
    "\t\tif art_str is not None:\n",
    "\t\t\ttrain_x, train_y = artificial_smote(train_x, train_y, art_str, under)\n",
    "\t\tif feat_sel_type is not None:\n",
    "\t\t\ttrain_x, test_x = feature_selection(train_x, train_y, test_x, feat_sel_type)\n",
    "\t\tif scaler_ref is not None:\n",
    "\t\t\ttrain_x, test_x = transform_num_data(train_x, test_x, scaler_ref, num_col)\n",
    "\t\tresult = dp.train_model_fetch_results(train_x, train_y, test_x, test_y, model_name, USE_AUC_TH)\n",
    "\t\tresult_list.append(result)\n",
    "\n",
    "\tresult_stat = result_statistics(result_list)\n",
    "\n",
    "\treturn result_stat\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------\n",
    "def test_ctgan_first(df, label_col, n_exec, model_name, rcorr=True, scaler_ref=None, num_col=None, feat_sel_type=None, art_str=None, savefile=None):\n",
    "\tresult_list = []\n",
    "\tproc_df = df\n",
    "\tif rcorr:\n",
    "\t\tproc_df = remove_corr_feat(proc_df, label_col)\n",
    "\tfor n in range(n_exec):\n",
    "\t\ttrain_x, test_x, train_y, test_y = dp.split_data(proc_df, label_col, test_size=0.25)\n",
    "\t\tif art_str is not None:\n",
    "\t\t\ttrain_x, train_y = artificial_ctgan(train_x, train_y, art_str, savefile)\n",
    "\t\tif feat_sel_type is not None:\n",
    "\t\t\ttrain_x, test_x = feature_selection(train_x, train_y, test_x, feat_sel_type)\n",
    "\t\tif scaler_ref is not None:\n",
    "\t\t\ttrain_x, test_x = transform_num_data(train_x, test_x, scaler_ref, num_col)\n",
    "\t\tresult = dp.train_model_fetch_results(train_x, train_y, test_x, test_y, model_name, USE_AUC_TH)\n",
    "\t\tresult_list.append(result)\n",
    "\n",
    "\tresult_stat = result_statistics(result_list)\n",
    "\n",
    "\treturn result_stat\n",
    "\n",
    "# -----------------------------------\n",
    "# -----------------------------------\n",
    "# -----------------------------------\n",
    "def plot_results(res_df, y_lim=[0.7, 1.0]):\n",
    "\tplt.figure().clear()\n",
    "\tplt.close()\n",
    "\tplt.cla()\n",
    "\tplt.clf()\n",
    "\n",
    "\tfig = plt.gcf()\n",
    "\tfig.set_size_inches(18, 10)\n",
    "\t#fig.set_dpi(100)\n",
    "\n",
    "\tsns.set_theme(style=\"whitegrid\")\n",
    "\tplt.ylim(y_lim[0], y_lim[1])\n",
    "\tax = sns.barplot(x=COL_METRIC, y=COL_VALUE, hue=COL_TEST, data=res_df)\n",
    "\tplt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0, fontsize=20)\n",
    "\t#ax.axes.set_title(\"Title\",fontsize=50)\n",
    "\tax.set_xlabel(COL_METRIC, fontsize=30)\n",
    "\tax.set_ylabel(COL_VALUE, fontsize=30)\n",
    "\tax.tick_params(labelsize=15)\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = database.load_wilt()\n",
    "label_col = \"class\"\n",
    "df[label_col] = df[label_col].replace({\"w\": 1, \"n\": 0})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = [\"GLCM_pan\", \"Mean_Green\", \"Mean_Red\", \"Mean_NIR\", \"SD_pan\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Efficiency of Different Classes from raimitigations.dataprocessing lib\n",
    "\n",
    "### KNN Model\n",
    "\n",
    "#### Data Transformations\n",
    "\n",
    "Here we compare 8 different training pipelines with a KNN model. For each pipeline, 50 runs are performed, and the mean and stdev of the metrics are computed and plotted in the graph below. \n",
    "- baseline dataset\n",
    "- baseline dataset, removal of correlated features\n",
    "- baseline dataset, removal of correlated features, standard scaler\n",
    "- baseline dataset, removal of correlated features, minmax scaler\n",
    "- baseline dataset, removal of correlated features, quantile transformer\n",
    "- baseline dataset, removal of correlated features, data normalizer\n",
    "- baseline dataset, removal of correlated features, robust scaler\n",
    "- baseline dataset, removal of correlated features, power transformer\n",
    "\n",
    "Note: Some of the experiments below take 10+ min to run. You may change `N_EXEC` to a smaller number to decrease the time it takes to run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"knn\"\n",
    "N_EXEC = 50\n",
    "\n",
    "\n",
    "result_base = test_base(df, label_col, N_EXEC, MODEL_NAME)\n",
    "result_df = add_results_df(None, result_base, \"Baseline\")\n",
    "\n",
    "result_cor = test_corr(df, label_col, N_EXEC, MODEL_NAME)\n",
    "result_df = add_results_df(result_df, result_cor, \"Corr.\")\n",
    "\n",
    "result_tr = test_corr_transf(df, label_col, N_EXEC, dp.DataStandardScaler, MODEL_NAME, num_col)\n",
    "result_df = add_results_df(result_df, result_tr, \"Std.\")\n",
    "\n",
    "result_tr = test_corr_transf(df, label_col, N_EXEC, dp.DataMinMaxScaler, MODEL_NAME, num_col)\n",
    "result_df = add_results_df(result_df, result_tr, \"Min/Max.\")\n",
    "\n",
    "result_tr = test_corr_transf(df, label_col, N_EXEC, dp.DataQuantileTransformer, MODEL_NAME, num_col)\n",
    "result_df = add_results_df(result_df, result_tr, \"Quantile\")\n",
    "\n",
    "result_tr = test_corr_transf(df, label_col, N_EXEC, dp.DataNormalizer, MODEL_NAME, num_col)\n",
    "result_df = add_results_df(result_df, result_tr, \"Normalizer\")\n",
    "\n",
    "result_tr = test_corr_transf(df, label_col, N_EXEC, dp.DataRobustScaler, MODEL_NAME, num_col)\n",
    "result_df = add_results_df(result_df, result_tr, \"Robust\")\n",
    "\n",
    "result_tr = test_corr_transf(df, label_col, N_EXEC, dp.DataPowerTransformer, MODEL_NAME, num_col)\n",
    "result_df = add_results_df(result_df, result_tr, \"Power\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection\n",
    "\n",
    "Now we will perform feature selection, where all features are removed from the dataset to improve the model performance. We will compare two different feature selection pipelines with two baseline models.\n",
    "- Baseline KNN model\n",
    "- KNN model with robust scaler\n",
    "- KNN model, robust scaler, sequential feature selection \n",
    "- KNN model, robust scaler, CatBoost feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"knn\"\n",
    "\n",
    "result_base = test_base(df, label_col, N_EXEC, MODEL_NAME)\n",
    "result_df = add_results_df(None, result_base, \"Baseline\")\n",
    "\n",
    "result_tr = test_corr_transf(df, label_col, N_EXEC, dp.DataRobustScaler, MODEL_NAME, num_col)\n",
    "result_df = add_results_df(result_df, result_tr, \"Robust\")\n",
    "\n",
    "restult_fs = test_smote_transf(df, label_col, N_EXEC, MODEL_NAME, rcorr=False, scaler_ref=dp.DataRobustScaler, num_col=num_col, feat_sel_type=SEQ_BWD)\n",
    "result_df = add_results_df(result_df, restult_fs, \"Seq.Bwd.Robust\")\n",
    "\n",
    "restult_fs = test_smote_transf(df, label_col, N_EXEC, MODEL_NAME, rcorr=False, scaler_ref=dp.DataRobustScaler, num_col=num_col, feat_sel_type=CATBOOST)\n",
    "result_df = add_results_df(result_df, restult_fs, \"CatBoost Robust\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Artificial Instances - SMOTE\n",
    "\n",
    "Since we have imbalanced classes (most trees are not diseased), we will experiment with creating artificial data.\n",
    "- baseline KNN model\n",
    "- baseline KNN model with robust scaler and removal of correlated features\n",
    "- KNN model, remove correlated features, SMOTE artificial data\n",
    "- KNN model, remove correlated features, robust scaler, SMOTE artificial data\n",
    "- KNN model, remove correlated features, SMOTE artificial data, TomekLink under sampling\n",
    "- KNN model, remove correlated features, robust scaler, SMOTE artificial data, TomekLink under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"knn\"\n",
    "\n",
    "result_base = test_base(df, label_col, N_EXEC, MODEL_NAME)\n",
    "result_df = add_results_df(None, result_base, \"Baseline\")\n",
    "\n",
    "result_tr = test_corr_transf(df, label_col, N_EXEC, dp.DataRobustScaler, MODEL_NAME, num_col)\n",
    "result_df = add_results_df(result_df, result_tr, \"Robust\")\n",
    "\n",
    "restult_fs = test_smote_transf(df, label_col, N_EXEC, MODEL_NAME, rcorr=True, scaler_ref=None, feat_sel_type=None, art_str=0.2, under=False)\n",
    "result_df = add_results_df(result_df, restult_fs, \"SM\")\n",
    "\n",
    "restult_fs = test_smote_transf(df, label_col, N_EXEC, MODEL_NAME, rcorr=True, scaler_ref=dp.DataRobustScaler, num_col=num_col, feat_sel_type=None, art_str=0.2, under=False)\n",
    "result_df = add_results_df(result_df, restult_fs, \"SM Robust\")\n",
    "\n",
    "restult_fs = test_smote_transf(df, label_col, N_EXEC, MODEL_NAME, rcorr=True, scaler_ref=None, feat_sel_type=None, art_str=0.2, under=True)\n",
    "result_df = add_results_df(result_df, restult_fs, \"SM+TK\")\n",
    "\n",
    "restult_fs = test_smote_transf(df, label_col, N_EXEC, MODEL_NAME, rcorr=True, scaler_ref=dp.DataRobustScaler, num_col=num_col, feat_sel_type=None, art_str=0.2, under=True)\n",
    "result_df = add_results_df(result_df, restult_fs, \"SM+TK Robust\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will compare different quantities of artificial instances generated (the float refers to the ratio of minority class to majority class). All of these models contain correlated feature removal and the robust scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"knn\"\n",
    "\n",
    "result_base = test_base(df, label_col, N_EXEC, MODEL_NAME)\n",
    "result_df = add_results_df(None, result_base, \"Baseline\")\n",
    "\n",
    "result_tr = test_corr_transf(df, label_col, N_EXEC, dp.DataRobustScaler, MODEL_NAME, num_col)\n",
    "result_df = add_results_df(result_df, result_tr, \"Robust\")\n",
    "\n",
    "restult_fs = test_smote_transf(df, label_col, N_EXEC, MODEL_NAME, rcorr=True, scaler_ref=dp.DataRobustScaler, num_col=num_col, feat_sel_type=None, art_str=0.1, under=False)\n",
    "result_df = add_results_df(result_df, restult_fs, \"SM Robust 0.1\")\n",
    "\n",
    "restult_fs = test_smote_transf(df, label_col, N_EXEC, MODEL_NAME, rcorr=True, scaler_ref=dp.DataRobustScaler, num_col=num_col, feat_sel_type=None, art_str=0.4, under=False)\n",
    "result_df = add_results_df(result_df, restult_fs, \"SM Robust 0.4\")\n",
    "\n",
    "restult_fs = test_smote_transf(df, label_col, N_EXEC, MODEL_NAME, rcorr=True, scaler_ref=dp.DataRobustScaler, num_col=num_col, feat_sel_type=None, art_str=0.6, under=False)\n",
    "result_df = add_results_df(result_df, restult_fs, \"SM Robust 0.6\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Artificial Instances - CTGAN\n",
    "\n",
    "Instead of doing over sampling using SMOTE and its variations, we can create artificial instances of the minority class using the CTGAN. Here we perform the following experiments:\n",
    "- KNN baseline model\n",
    "- baseline KNN model with robust scaler and removal of correlated features\n",
    "- KNN model, robust scaler, removal of correlated features, over sampling with CTGAN ratio of 0.15\n",
    "- KNN model, robust scaler, removal of correlated features, over sampling with CTGAN ratio of 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"knn\"\n",
    "\n",
    "result_base = test_base(df, label_col, N_EXEC, MODEL_NAME)\n",
    "result_df = add_results_df(None, result_base, \"Baseline\")\n",
    "\n",
    "result_tr = test_corr_transf(df, label_col, N_EXEC, dp.DataRobustScaler, MODEL_NAME, num_col)\n",
    "result_df = add_results_df(result_df, result_tr, \"Robust\")\n",
    "\n",
    "restult_fs = test_ctgan_first(df, label_col, N_EXEC, MODEL_NAME, rcorr=True, scaler_ref=dp.DataRobustScaler, num_col=num_col, feat_sel_type=None, art_str=0.15, savefile=\"2_1.pkl\")\n",
    "result_df = add_results_df(result_df, restult_fs, \"CTGAN 0.15 Robust\")\n",
    "\n",
    "restult_fs = test_ctgan_first(df, label_col, N_EXEC, MODEL_NAME, rcorr=True, scaler_ref=dp.DataRobustScaler, num_col=num_col, feat_sel_type=None, art_str=0.3, savefile=\"2_2.pkl\")\n",
    "result_df = add_results_df(result_df, restult_fs, \"CTGAN 0.3 Robust\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "After the extensive experimenting with KNN models, we can also perform the same comparisons of experiments with XGBoost models instead. The following cells demonstrate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"xgb\"\n",
    "\n",
    "result_base = test_base(df, label_col, N_EXEC, MODEL_NAME)\n",
    "result_df = add_results_df(None, result_base, \"Baseline\")\n",
    "\n",
    "result_cor = test_corr(df, label_col, N_EXEC, MODEL_NAME)\n",
    "result_df = add_results_df(result_df, result_cor, \"Corr.\")\n",
    "\n",
    "result_tr = test_corr_transf(df, label_col, N_EXEC, dp.DataStandardScaler, MODEL_NAME, num_col)\n",
    "result_df = add_results_df(result_df, result_tr, \"Std.\")\n",
    "\n",
    "result_tr = test_corr_transf(df, label_col, N_EXEC, dp.DataMinMaxScaler, MODEL_NAME, num_col)\n",
    "result_df = add_results_df(result_df, result_tr, \"Min/Max.\")\n",
    "\n",
    "result_tr = test_corr_transf(df, label_col, N_EXEC, dp.DataQuantileTransformer, MODEL_NAME, num_col)\n",
    "result_df = add_results_df(result_df, result_tr, \"Quantile\")\n",
    "\n",
    "result_tr = test_corr_transf(df, label_col, N_EXEC, dp.DataNormalizer, MODEL_NAME, num_col)\n",
    "result_df = add_results_df(result_df, result_tr, \"Normalizer\")\n",
    "\n",
    "result_tr = test_corr_transf(df, label_col, N_EXEC, dp.DataRobustScaler, MODEL_NAME, num_col)\n",
    "result_df = add_results_df(result_df, result_tr, \"Robust\")\n",
    "\n",
    "result_tr = test_corr_transf(df, label_col, N_EXEC, dp.DataPowerTransformer, MODEL_NAME, num_col)\n",
    "result_df = add_results_df(result_df, result_tr, \"Power\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_base = test_base(df, label_col, N_EXEC, MODEL_NAME)\n",
    "result_df = add_results_df(None, result_base, \"Baseline\")\n",
    "\n",
    "restult_fs = test_smote_transf(df, label_col, N_EXEC, MODEL_NAME, rcorr=True, scaler_ref=None, feat_sel_type=SEQ_BWD)\n",
    "result_df = add_results_df(result_df, restult_fs, \"Seq.Bwd.Qtl.\")\n",
    "\n",
    "restult_fs = test_smote_transf(df, label_col, N_EXEC, MODEL_NAME, rcorr=True, scaler_ref=None, feat_sel_type=CATBOOST)\n",
    "result_df = add_results_df(result_df, restult_fs, \"CatBoost Qtl.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result_df, y_lim=[0.6,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"xgb\"\n",
    "result_base = test_base(df, label_col, N_EXEC, MODEL_NAME)\n",
    "result_df = add_results_df(None, result_base, \"Baseline\")\n",
    "\n",
    "restult_fs = test_ctgan_first(df, label_col, N_EXEC, MODEL_NAME, rcorr=True, scaler_ref=None, feat_sel_type=None, art_str=0.1, savefile=\"2_3.pkl\")\n",
    "result_df = add_results_df(result_df, restult_fs, \"CTGAN 0.1\")\n",
    "\n",
    "restult_fs = test_ctgan_first(df, label_col, N_EXEC, MODEL_NAME, rcorr=True, scaler_ref=None, feat_sel_type=None, art_str=0.15, savefile=\"2_4.pkl\")\n",
    "result_df = add_results_df(result_df, restult_fs, \"CTGAN 0.15\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result_df, y_lim=[0.6,1.0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('rai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84fbc7b41fd4e2e5309bc9ceaf402b3256461a3db19b05c6b76455652ef11b9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
