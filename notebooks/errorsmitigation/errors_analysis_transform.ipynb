{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e3bee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../ResponsibleAIToolbox-Mitigation/')\n",
    "\n",
    "import pandas as pd\n",
    "from errorsmitigation.dataprocessing import DataTransformer\n",
    "\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# print(__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc85b7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department</th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>recruitment_channel</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>is_promoted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_7</td>\n",
       "      <td>Master's &amp; above</td>\n",
       "      <td>f</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Operations</td>\n",
       "      <td>region_22</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_19</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_23</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Technology</td>\n",
       "      <td>region_26</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          department     region         education gender recruitment_channel  \\\n",
       "0  Sales & Marketing   region_7  Master's & above      f            sourcing   \n",
       "1         Operations  region_22        Bachelor's      m               other   \n",
       "2  Sales & Marketing  region_19        Bachelor's      m            sourcing   \n",
       "3  Sales & Marketing  region_23        Bachelor's      m               other   \n",
       "4         Technology  region_26        Bachelor's      m               other   \n",
       "\n",
       "   no_of_trainings  age  previous_year_rating  length_of_service  \\\n",
       "0                1   35                   5.0                  8   \n",
       "1                1   30                   5.0                  4   \n",
       "2                1   34                   3.0                  7   \n",
       "3                2   39                   1.0                 10   \n",
       "4                1   45                   3.0                  2   \n",
       "\n",
       "   KPIs_met >80%  awards_won?  avg_training_score  is_promoted  \n",
       "0              1            0                  49            0  \n",
       "1              0            0                  60            0  \n",
       "2              0            0                  50            0  \n",
       "3              0            0                  50            0  \n",
       "4              0            0                  73            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '../../datasets/hr_promotion'\n",
    "dataset =  pd.read_csv(data_dir + '/train.csv').drop(['employee_id'], axis=1)\n",
    "seed =42\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7b70702",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      0          1                 2         3  4   5    6   \\\n",
      "0      Sales & Marketing   region_7  Master's & above  sourcing  1  35  5.0   \n",
      "1             Operations  region_22        Bachelor's     other  1  30  5.0   \n",
      "2      Sales & Marketing  region_19        Bachelor's  sourcing  1  34  3.0   \n",
      "3      Sales & Marketing  region_23        Bachelor's     other  2  39  1.0   \n",
      "4             Technology  region_26        Bachelor's     other  1  45  3.0   \n",
      "...                  ...        ...               ...       ... ..  ..  ...   \n",
      "54803         Technology  region_14        Bachelor's  sourcing  1  48  3.0   \n",
      "54804         Operations  region_27  Master's & above     other  1  37  2.0   \n",
      "54805          Analytics   region_1        Bachelor's     other  1  27  5.0   \n",
      "54806  Sales & Marketing   region_9               NaN  sourcing  1  29  1.0   \n",
      "54807                 HR  region_22        Bachelor's     other  1  27  1.0   \n",
      "\n",
      "       7  8  9   10 11        12        13  \n",
      "0       8  1  0  49  0  1.536223 -1.536223  \n",
      "1       4  0  0  60  0 -0.650947  0.650947  \n",
      "2       7  0  0  50  0 -0.650947  0.650947  \n",
      "3      10  0  0  50  0 -0.650947  0.650947  \n",
      "4       2  0  0  73  0 -0.650947  0.650947  \n",
      "...    .. .. ..  .. ..       ...       ...  \n",
      "54803  17  0  0  78  0 -0.650947  0.650947  \n",
      "54804   6  0  0  56  0  1.536223 -1.536223  \n",
      "54805   3  1  0  79  0 -0.650947  0.650947  \n",
      "54806   2  0  0  45  0 -0.650947  0.650947  \n",
      "54807   5  0  0  49  0 -0.650947  0.650947  \n",
      "\n",
      "[54808 rows x 14 columns]\n",
      "StandardScaler transformer\n",
      "\n",
      "MinMaxScaler transformer\n",
      "\n",
      "RobustScaler transformer\n",
      "\n",
      "PowerTransformer transformer\n",
      "\n",
      "QuantileTransformer transformer\n",
      "\n",
      "Normalizer transformer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Parameters\n",
    "\n",
    "# dataset - A Panda Data Frame representing the data to transform. \n",
    "# target â€“ A string representing the name of the label column, or the label column integer index (zero base)\n",
    "\n",
    "# transformer_type - Enum object for available transformations. \n",
    "    # StandardScaler: sklearn.preprocessing.StandardScaler  \n",
    "        # Standardize features by removing the mean and scaling to unit variance.   \n",
    "        # z = (x - u) / s (where u is the mean of the training samples or zero if with_mean=False, and s is the standard \n",
    "        # deviation of the training samples or one if with_std=False). \n",
    "    # MinMaxScaler: sklearn.preprocessing.MinMaxScaler \n",
    "        # Transform features by scaling each feature to a given range. This estimator scales and translates each feature \n",
    "        # individually such that it is in the given range on the training set, e.g. between zero and one.  \n",
    "    # RobustScaler: sklearn.preprocessing.RobustScaler \n",
    "        # Scale features using statistics that are robust to outliers. This Scaler removes the median and scales the data \n",
    "        # according to the quantile range (defaults to IQR: Interquartile Range). The IQR is the range between the 1st \n",
    "        # quartile (25th quantile) and the 3rd quartile (75th quantile).  \n",
    "    # PowerTransformer: sklearn.preprocessing.PowerTransformer \n",
    "        # Apply a power transform feature-wise to make data more Gaussian-like. This is useful for modeling issues related \n",
    "        # to heteroscedasticity (non-constant variance), or other situations where normality is desired. \n",
    "        # Box-Cox transform requires input data to be strictly positive, while Yeo-Johnson supports both positive and negative data.  \n",
    "    # QuantileTransformer: sklearn.preprocessing.QuantileTransformer \n",
    "        # Transform features using quantiles information. This method transforms the features to follow a uniform or a normal \n",
    "        # distribution. Therefore, for a given feature, this transformation tends to spread out the most frequent values. \n",
    "        # It also reduces the impact of (marginal) outliers: this is therefore a robust preprocessing scheme.  \n",
    "    # Normaliser: sklearn.preprocessing.Normalizer \n",
    "        # Normalize samples individually to unit norm. Each sample (i.e. each row of the data matrix) with at least one \n",
    "        # nonzero component is rescaled independently of other samples so that its norm (l1, l2 or inf) equals one. \n",
    "        \n",
    "#  â€“ List of the features to transform. The list could be the indexes or the names of the features. \n",
    "\n",
    "# random_state - Control the randomization of the algorithm. \n",
    "    # â€˜Noneâ€™: the random number generator is the RandomState instance used by np.random.\n",
    "\n",
    "# method - {â€˜yeo-johnsonâ€™, â€˜box-coxâ€™}, default=â€™yeo-johnsonâ€™  \n",
    "\n",
    "# output_distribution - {â€˜uniformâ€™, â€˜normalâ€™}, Marginal distribution for the transformed data. The choices are \n",
    "    # â€˜uniformâ€™ (default) or â€˜normalâ€™.\n",
    "    \n",
    "# transform_features = ['department', 'region', 'education','gender', 'recruitment_channel']\n",
    "# transform_features = [6,7,8]\n",
    "\n",
    "\n",
    "target_index = dataset.columns.get_loc('is_promoted')\n",
    "\n",
    "# standard_scaler =  DataTransformer(dataset, 'is_promoted',DataTransformer.TransformerType.StandardScaler, None, seed)\n",
    "standard_scaler =  DataTransformer(dataset, target_index, DataTransformer.TransformerType.StandardScaler, None, seed)\n",
    "print(standard_scaler.Transform())\n",
    "print('StandardScaler transformer')\n",
    "print('')\n",
    "\n",
    "minmax_scaler =  DataTransformer(dataset, 'is_promoted', DataTransformer.TransformerType.MinMaxScaler, None, seed)\n",
    "minmax_scaler.Transform()\n",
    "print('MinMaxScaler transformer')\n",
    "print('')\n",
    "\n",
    "robust_scaler =  DataTransformer(dataset, 'is_promoted', DataTransformer.TransformerType.RobustScaler, None, seed)\n",
    "robust_scaler.Transform()\n",
    "print('RobustScaler transformer')\n",
    "print('')\n",
    "\n",
    "power_transformer =  DataTransformer(dataset, 'is_promoted', DataTransformer.TransformerType.PowerTransformer, None, seed)\n",
    "power_transformer.Transform()\n",
    "print('PowerTransformer transformer')\n",
    "print('')\n",
    "\n",
    "quantile_transformer =  DataTransformer(dataset, 'is_promoted', DataTransformer.TransformerType.QuantileTransformer, None, seed)\n",
    "quantile_transformer.Transform()\n",
    "print('QuantileTransformer transformer')\n",
    "print('')\n",
    "\n",
    "normaliser =  DataTransformer(dataset, 'is_promoted', DataTransformer.TransformerType.Normalizer, None, seed)\n",
    "normaliser.Transform()\n",
    "print('Normalizer transformer')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43031c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler transformer\n",
      "\n",
      "StandardScaler transformer for: ['department', 'region']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_index = dataset.columns.get_loc('is_promoted')\n",
    "\n",
    "# transform all data\n",
    "standard_scaler =  DataTransformer(dataset, 'is_promoted',DataTransformer.TransformerType.StandardScaler, None, seed)\n",
    "standard_scaler.Transform()\n",
    "print('StandardScaler transformer')\n",
    "print('')\n",
    "\n",
    "# Transform specific features\n",
    "transform_features = ['department', 'region']\n",
    "# transform_features = [0,1]\n",
    "\n",
    "standard_scaler =  DataTransformer(dataset, target_index,DataTransformer.TransformerType.StandardScaler, transform_features, seed)\n",
    "standard_scaler.Transform()\n",
    "print('StandardScaler transformer for: ' + str(transform_features))\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193967f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
