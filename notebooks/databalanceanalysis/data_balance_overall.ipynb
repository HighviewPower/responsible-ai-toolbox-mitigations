{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Data Balance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context\n",
    "Data Balance Analysis is relevant for overall understanding of datasets, but it becomes essential when thinking about building Machine Learning models in a responsible way, especially in term of fairness. It is all too easy to build an ML Model that produced biased results for subsets of the population by training or testing the model of biased ground truth data. There are multiple case studies of biased models assisting in granting loans healthcare, recruitment opportunities and many other decision making tasks. In most of these examples, the data from which these models are trained was the common issue. These findings emphasize how important it is for model creators and auditors to analysis data balance: to measure training data across various sub-populations and ensure the data has good coverage and a balanced representation of labels across sensitive categories adn category combinations and to check that test data is representative of the target population\n",
    "\n",
    "In summary, Data Balance Analysis when used a step for building ML models has the following benefits: \n",
    "- reduces the risk of unbalanced models, ensuring service fairness and reducing the costs of ML building by identifying data representation gaps early on and prompting data scientists to seek mitigation steps before proceeding on the training portion of Machine Learning model development\n",
    "- Enables easy end-to-end debugging of ML systems in combination with Fairlearn by providing a clear view if an issue in a model is tied to the data or the model itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage \n",
    "Data Balance Analysis supports three different types of metrics. \n",
    "- FeatureMeasures - supervised (requires a label column)\n",
    "- DistributionMeasures - unsupervised (does not require a label column)\n",
    "- AggregateMeasures - unsupervised (does not require a label column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First we import all of the classes we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'databalanceanalysis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34272/4175325324.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdatabalanceanalysis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatabalanceanalysis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maggregate_measures\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAggregateMeasures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatabalanceanalysis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatabalanceanalysis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_measures\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFeatureMeasures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatabalanceanalysis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatabalanceanalysis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribution_measures\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDistributionMeasures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'databalanceanalysis'"
     ]
    }
   ],
   "source": [
    "from databalanceanalysis.databalanceanalysis.aggregate_measures import AggregateMeasures\n",
    "from databalanceanalysis.databalanceanalysis.feature_measures import FeatureMeasures\n",
    "from databalanceanalysis.databalanceanalysis.distribution_measures import DistributionMeasures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the dataset, define the features of interest and ensure that the label column is binary. Currently, the FeatureBalance measure calculator only supports binary labels. \n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sensitive_features = [\"Gender\", \"Race\"]\n",
    "\n",
    "df =  pd.read_csv('datasets/AdultCensusIncome.csv')\n",
    "\n",
    "# convert to 0 and 1 encoding\n",
    "dataset['income'] = dataset['income'].apply(lambda x: 0 if x == \"<=50K\" else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create an instance of the FeatureMeasure class and set the sensitives to the column you are interested in seeing and the label column to the name of the column of interest.\n",
    "\n",
    "For example: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create an instance of the DistributionMeasures class and set the sensitive columns to the columns you are interested in seeing. \n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create an instance of the AggregateMeasures class and set the sensitive columns parameter to the columns of interest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanations of Data Balance Measures\n",
    "### Feature Balance Measures\n",
    "Feature Balance Measures allow us to see whether each combination of sensitive feature is receiving the positive outcome (true prediction) at balanced probability.\n",
    "\n",
    "In this context, we define a feature balance measure, also referred to as the parity, for label y as the difference between the association metrics of two different sensitive classes $([x_A, x_B])$, with respect to the association metric $(A(x_i, y))$. That is:\n",
    "\n",
    "$$parity(y \\vert x_A, x_B, A(\\cdot)) \\coloneqq A(x_A, y) - A(x_B, y) $$\n",
    "\n",
    "Using the dataset, we can see if the various sexes and races are receiving >50k income at equal or unequal rates.\n",
    "\n",
    "Note: Many of these metrics were influenced by this paper [Measuring Model Biases in the Absence of Ground Truth.](https://arxiv.org/abs/2103.03417)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Association Metric | Family | Description | Interpretation | Reference\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Demographic Parity | Fairness | Proportion of each segment of a protected class (e.g. gender) should receive the positive outcome at equal rates.\t| As close to 0 means better parity. $(DP = P(Y \\vert A = Male) - P(Y \\vert A = Female))$. Y = Positive label rate.| [Link](https://en.wikipedia.org/wiki/Fairness_%28machine_learning%29) |\n",
    "|Pointwise Mutual Information (PMI), normalized PMI | Entropy\t|The PMI of a pair of feature values (ex: Gender=Male and Gender=Female) quantifies the discrepancy between the probability of their coincidence given their joint distribution and their individual distributions (assuming independence). | Range (normalized) [-1, 1]. -1 for no co-occurences. 0 for co-occurences at random. 1 for complete co-occurences.| [Link](https://en.wikipedia.org/wiki/Pointwise_mutual_information) |\n",
    "| Sorensen-Dice Coefficient (SDC) | Intersection-over-Union| Union\tUsed to gauge the similarity of two samples. Related to F1 score. |Equals twice the number of elements common to both sets divided by the sum of the number of elements in each set. | [Link]() | \n",
    "|Jaccard Index | Intersection-over-Union | Similar to SDC, guages the similarity and diversity of sample sets. | Equals the size of the intersection divided by the size of the union of the sample sets. | [Link] | \n",
    "|Kendall Rank Correlation | Correlation and Statistical Tests | Used to measure the ordinal association between two measured quantities. | High when observations have a similar rank and low when observations have a dissimilar rank between the two variables. |[Link] |\n",
    "|Log-Likelihood Ratio | Correlation and Statistical Tests |  Statistical Tests\tCalculates the degree to which data supports one variable versus another. Log of the likelihood ratio, which gives the probability of correctly predicting the label in ratio to probability of incorrectly predicting label. | If likelihoods are similar, it should be close to 0. |[Link] | \n",
    "|t-test | Correlation and Statistical Tests | Used to compare the means of two groups (pairwise). | Value looked up in t-Distribution tell if statistically significant or not. |[Link] | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: This notebook is adaptation of this notebook in the SynapseML documentation https://microsoft.github.io/SynapseML/docs/features/responsible_ai/Data%20Balance%20Analysis/ written by Kashyap Patel"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25553ff2aeabf811aa6253044d4e27aa04c210fdd185f9aa4a44c307365de193"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('ischiadev': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
