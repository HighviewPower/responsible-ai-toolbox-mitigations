{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../../ResponsibleAIToolbox-Mitigation/')\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "from errorsmitigation.dataprocessing import DataRebalance\n",
    "from errorsmitigation.dataprocessing import DataSplit\n",
    "from databalanceanalysis.databalanceanalysis.utils import undummify\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "data_dir = '../datasets/hr_promotion'\n",
    "df =  pd.read_csv(data_dir + '/train.csv').drop(['employee_id'], axis=1)\n",
    "cols_of_interest = ['education', 'gender']\n",
    "label_col = 'is_promoted'\n",
    "seed = 42\n",
    "# handle duplicates\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train a model and get accuracy numbers\n",
    "\n",
    "# data prep\n",
    "def split_label(dataset):\n",
    "    x = dataset.drop(['is_promoted'], axis=1)\n",
    "    y = dataset['is_promoted']\n",
    "    return x, y\n",
    "\n",
    "dataset = pd.get_dummies(df, drop_first=False)\n",
    "target_index = dataset.columns.get_loc('is_promoted')\n",
    "data_split =  DataSplit(dataset,target_index , 0.9, 42, True, False, False, True)\n",
    "train_data, test_data = data_split.Split()\n",
    "# splitting the training data\n",
    "x_train, y_train = split_label(train_data)\n",
    "# splitting the test data\n",
    "x_test, y_test = split_label(test_data)\n",
    "\n",
    "# LGBMClassifier Model\n",
    "clf = LGBMClassifier(n_estimators=50)\n",
    "model = clf.fit(x_train, y_train)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "def conf_matrix(y,pred):\n",
    "    ((tn, fp), (fn, tp)) = metrics.confusion_matrix(y, pred)\n",
    "    ((tnr,fpr),(fnr,tpr))= metrics.confusion_matrix(y, pred, normalize='true')\n",
    "    return pd.DataFrame([[f'TP = {tp} ({tpr:1.2%})', f'FN = {fn} ({fnr:1.2%})'], \n",
    "                         [f'FP = {fp} ({fpr:1.2%})', f'TN = {tn} ({tnr:1.2%})']],\n",
    "                        index=['True', 'False'], \n",
    "                        columns=['Pred 1', 'Pred 0'])\n",
    "\n",
    "print(\"number of errors on test dataset: \" + str(sum(pred != y_test)))\n",
    "\n",
    "conf_matrix(y_test,pred)\n",
    "\n",
    "print(classification_report(y_test, pred)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databalanceanalysis.databalanceanalysis.feature_measures import FeatureBalanceMeasure\n",
    "\n",
    "feature_measures = FeatureBalanceMeasure( cols_of_interest, label_col)\n",
    "\n",
    "feat_measures1 = feature_measures.measures(df)\n",
    "feat_measures1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databalanceanalysis.databalanceanalysis.distribution_measures import DistributionBalanceMeasure\n",
    "\n",
    "dist_measures = DistributionBalanceMeasure( cols_of_interest)\n",
    "dist_measures1 = dist_measures.measures(df)\n",
    "dist_measures1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databalanceanalysis.databalanceanalysis.aggregate_measures import AggregateBalanceMeasure\n",
    "\n",
    "agg_measures = AggregateBalanceMeasure( cols_of_interest)\n",
    "agg_measures1 = agg_measures.measures(df)\n",
    "agg_measures1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_tomek = SMOTETomek()\n",
    "smote = SMOTE()\n",
    "tomek = TomekLinks()\n",
    "dummy_df = pd.get_dummies(df, prefix_sep = \"-\")\n",
    "dummy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df = undummify(dummy_df, prefix_sep = \"-\", col = 'gender')\n",
    "gender_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balance_smote =  DataRebalance(gender_df, 'gender', 'auto', 42, None, smote, None)\n",
    "\n",
    "print(gender_df.shape)\n",
    "smote_df = data_balance_smote.Rebalance()\n",
    "print(smote_df.shape)\n",
    "# smote_df\n",
    "# print(smote_df.head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(smote_df.shape)\n",
    "# smote_df.head()\n",
    "# dummy_df = pd.get_dummies(smote_df, prefix_sep =\"-\") # not required\n",
    "# print(dummy_df.shape)\n",
    "# dummy_df.head()\n",
    "\n",
    "smote_df.head()\n",
    "education_df = undummify(smote_df, prefix_sep = \"-\", col = 'education')\n",
    "education_df.head()\n",
    "\n",
    "education_df['education'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balance_smote_2 =  DataRebalance(education_df, 'education', 'auto', 42, None, smote, None)\n",
    "\n",
    "print(education_df.shape)\n",
    "smote_df_2 = data_balance_smote_2.Rebalance()\n",
    "print(smote_df_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_index = smote_df_2.columns.get_loc('is_promoted')\n",
    "data_split =  DataSplit(smote_df_2,target_index , 0.9, 42, False, False, False, True)\n",
    "train_data, test_data = data_split.Split()\n",
    "# splitting the training data\n",
    "x_train2, y_train2 = split_label(train_data)\n",
    "# splitting the test data\n",
    "x_test2, y_test2 = split_label(test_data)\n",
    "\n",
    "# LGBMClassifier Model\n",
    "clf2 = LGBMClassifier(n_estimators=50)\n",
    "model2 = clf2.fit(x_train2, y_train2)\n",
    "\n",
    "pred2 = model2.predict(x_test2)\n",
    "\n",
    "def conf_matrix(y,pred):\n",
    "    ((tn, fp), (fn, tp)) = metrics.confusion_matrix(y, pred)\n",
    "    ((tnr,fpr),(fnr,tpr))= metrics.confusion_matrix(y, pred, normalize='true')\n",
    "    return pd.DataFrame([[f'TP = {tp} ({tpr:1.2%})', f'FN = {fn} ({fnr:1.2%})'], \n",
    "                         [f'FP = {fp} ({fpr:1.2%})', f'TN = {tn} ({tnr:1.2%})']],\n",
    "                        index=['True', 'False'], \n",
    "                        columns=['Pred 1', 'Pred 0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Results\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "\n",
    "\n",
    "print('')\n",
    "print(color.PURPLE + color.BOLD + \"BEFORE: \" + color.END + \"number of test dataset instances: \" + color.BOLD   + color.GREEN + str(len(y_test)) + color.END)\n",
    "print(\"      : number of errors on test dataset: \" + color.BOLD   + color.RED + str(sum(pred != y_test)) + color.END)\n",
    "print('')\n",
    "print(color.PURPLE + color.BOLD + \"AFTER:  \" + color.END + \"number of test dataset instances: \" + color.BOLD   + color.GREEN + str(len(y_test2)) + color.END)\n",
    "print(\"     :  number of errors on test dataset: \" + color.BOLD  + color.RED + str(sum(pred2 != y_test2)) + color.END)\n",
    "print('')\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "print('')\n",
    "print(color.BLUE + color.BOLD +\"BEFORE: conf_matrix:\" + color.END)\n",
    "print(\"--------------------\")\n",
    "conf_matrix(y_test,pred) \n",
    "print('')\n",
    "print(color.BLUE + color.BOLD +\"AFTER: conf_matrix:\" + color.END)\n",
    "print(\"-------------------\")\n",
    "conf_matrix(y_test2,pred2)\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "print('')\n",
    "print(color.YELLOW + color.BOLD +\"BEFORE: classification_report:\" + color.END)\n",
    "print(\"--------------------------------\")\n",
    "print(classification_report(y_test, pred)) \n",
    "print(color.YELLOW + color.BOLD +\"AFTER: classification_report:\" + color.END)\n",
    "print(\"--------------------------------\")\n",
    "print(classification_report(y_test2, pred2)) \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_measures.measures(education_df)\n",
    "feat_measures1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_measures.measures(education_df)\n",
    "dist_measures1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_measures.measures(education_df)\n",
    "agg_measures1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IGNORE BELOW FOR NOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df = undummify(dummy_df, prefix_sep = \"-\", col_list = ['race'])\n",
    "data_rebalance_smote =  DataRebalance(race_df, 'race', None, None, None, smote, None)\n",
    "data_rebalance_tomek = DataRebalance(race_df, 'race', None, None, None, None, None)\n",
    "data_rebalance_smote_tomek = DataRebalance(race_df, 'race', None, None, None, None, None)\n",
    "smote_df = data_rebalance_smote.Rebalance()\n",
    "tomek_df = data_rebalance_tomek.Rebalance()\n",
    "smote_tomek_df = data_rebalance_smote_tomek.Rebalance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = undummify(df, \"-\")\n",
    "# smote_df = undummify(smote_df, \"-\")\n",
    "# smote_tomek_df = undummify(smote_tomek_df, \"-\")\n",
    "# tomek_df = undummify(tomek_df, \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_sex_df = undummify( pd.get_dummies(smote_df, prefix_sep= \"-\"), prefix_sep = \"-\", col_list = [\"sex\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomek_sex_df = undummify( pd.get_dummies(tomek_df, prefix_sep= \"-\"), prefix_sep = \"-\", col_list = [\"sex\"]) \n",
    "smote_tomek_sex_df = undummify( pd.get_dummies(smote_tomek_df, prefix_sep= \"-\"), prefix_sep = \"-\", col_list = [\"sex\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rebalance_smote =  DataRebalance(smote_sex_df, 'sex', None, None, None, smote, None)\n",
    "data_rebalance_tomek = DataRebalance(tomek_sex_df, 'sex', None, None, None, None, None)\n",
    "data_rebalance_smote_tomek = DataRebalance(smote_tomek_sex_df, 'sex', None, None, None, None, None)\n",
    "smote_df = data_rebalance_smote.Rebalance()\n",
    "tomek_df = data_rebalance_tomek.Rebalance()\n",
    "# smote_tomek_df = data_rebalance_smote_tomek.Rebalance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_df = undummify()\n",
    "tomek_df = undummify()\n",
    "# smote_tomek_df = undummify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databalanceanalysis.databalanceanalysis.feature_measures import FeatureBalanceMeasure\n",
    "feat_measures = feature_measures.measures(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First look at the feature balance measures for the dataset without applying SMOTE or TOMEK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying SMOTE method, these are the feature balance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_measures.measures(smote_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying applying the SMOTE-Tomek Method these are the feature balance measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_measures.measures(smote_tomek_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After appying the Tomek Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_measures.measures(tomek_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databalanceanalysis.databalanceanalysis.distribution_measures import DistributionBalanceMeasure\n",
    "dist_measures = DistributionBalanceMeasure(cols_of_interest)\n",
    "dist_measures.measures(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_measures.measures(smote_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_measures.measures(smote_tomek_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_measures.measures(tomek_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databalanceanalysis.databalanceanalysis.aggregate_measures import AggregateBalanceMeasure\n",
    "agg_measures = AggregateBalanceMeasure(cols_of_interest)\n",
    "agg_measures.measures(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_measures.measures(smote_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_measures.measures(smote_tomek_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_measures.measures(tomek_df)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25553ff2aeabf811aa6253044d4e27aa04c210fdd185f9aa4a44c307365de193"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
